{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake\n",
    "2024-02-01\n",
    "\n",
    "This is an example analysis of the Earthquake data for Haiti\n",
    "\n",
    "Earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from climada.util.api_client import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake = client.get_hazard(\"earthquake\", properties={\n",
    "                        \"country_iso3alpha\": \"HTI\",\n",
    "                    })\n",
    "earthquakes = []\n",
    "for i, event_intensity in enumerate(earthquake.intensity):\n",
    "    total_intensity = max(event_intensity.toarray().flatten())\n",
    "    if total_intensity > 0.0:\n",
    "        event_date = dt.datetime.fromordinal(earthquake.date[i]).isoformat()[0:10]\n",
    "        # print(event_date, total_intensity)\n",
    "        earthquakes.append([event_date, total_intensity])\n",
    "earthquake_dt = pd.DataFrame(earthquakes)\n",
    "earthquake_dt.columns= [\"date\", \"total intensity\"]\n",
    "earthquake_dt.plot(y=\"total intensity\",x=\"date\", kind=\"bar\")\n",
    "print(f\"Number of earthquakes:{len(earthquakes)}\", flush=True)\n",
    "average_max_intensity = statistics.mean([x[1] for x in earthquakes]) \n",
    "overall_max_intensity = max([x[1] for x in earthquakes])\n",
    "print(f\"Average max intensity: {round(average_max_intensity,2)}\", flush=True)\n",
    "print(f\"Overall max intensity: {round(overall_max_intensity,2)}\", flush=True)\n",
    "earthquake.plot_intensity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calc_zoom(df):\n",
    "  width_y = max(df[\"latitude\"]) - min(df[\"latitude\"])\n",
    "  width_x = max(df[\"longitude\"]) - min(df[\"longitude\"])\n",
    "  zoom_y = -1.446*math.log(width_y) + 7.2753\n",
    "  zoom_x = -1.415*math.log(width_x) + 8.7068\n",
    "  return min(round(zoom_y,2),round(zoom_x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "max_intensity = np.max(earthquake.intensity, axis=0).toarray().flatten()\n",
    "\n",
    "latitudes = earthquake.centroids.lat\n",
    "longitudes = earthquake.centroids.lon\n",
    "country_data = pd.DataFrame({\"latitude\":latitudes, \"longitude\":longitudes, \"value\":max_intensity})\n",
    "country_data[\"value\"] = (country_data[\"value\"]- min(country_data[\"value\"])) \n",
    "zoom = calc_zoom(country_data)\n",
    "fig = px.scatter_mapbox(country_data, \n",
    "                        lat=\"latitude\", lon=\"longitude\",\n",
    "                        color=\"value\",\n",
    "                        size=\"value\", size_max=20, \n",
    "                        zoom=zoom, opacity=0.75, \n",
    "                         mapbox_style='carto-darkmatter',\n",
    "\n",
    "                         width=1200, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdx_scraper_climada.climada_interface import calculate_earthquake_timeseries_admin2\n",
    "from hdx_scraper_climada.download_admin1_geometry import get_admin2_shapes_from_hdx\n",
    "# earthquakes = calculate_earthquake_timeseries_admin2(\"Haiti\")\n",
    "\n",
    "admin1_names, admin2_names, admin2_shapes = get_admin2_shapes_from_hdx(\"HTI\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small change to check nbstripout is working\n",
    "import geopandas\n",
    "import pandas\n",
    "all_shapes = geopandas.GeoDataFrame( pandas.concat(admin2_shapes, ignore_index=True) )\n",
    "all_shapes[\"admin1_names\"] = admin1_names\n",
    "all_shapes[\"admin2_names\"] = admin2_names\n",
    "all_shapes.plot(column = \"admin2_names\", categorical=True, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"admin1-timeseries-summaries.csv\", encoding=\"utf-8\") as summary_file:\n",
    "    summary_data = list(csv.DictReader(summary_file))\n",
    "\n",
    "date_set = set(x[\"event_date\"] for x in summary_data)\n",
    "print(date_set, flush=True)\n",
    "values = {x[\"admin2_name\"]:x[\"value\"] for x in summary_data if x[\"event_date\"] == \"2010-01-13\"}\n",
    "value_column = [float(values.get(x, 0.0)) for x in admin2_names]\n",
    "all_shapes = geopandas.GeoDataFrame( pandas.concat(admin2_shapes, ignore_index=True) )\n",
    "all_shapes[\"admin1_names\"] = admin1_names\n",
    "all_shapes[\"admin2_names\"] = admin2_names\n",
    "all_shapes[\"value\"] = value_column\n",
    "all_shapes.plot(column = \"value\", cmap='Spectral', legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
